{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Restructuring Notebook\n",
    "Let the carnage begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up things for Colab and non-Colab (just in case...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if colab := 'google_colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    # in case we'll do a shared drive, this will have to be changed.\n",
    "    # For now it is basically a placeholder\n",
    "    BASE_PATH = \"drive/MyDrive/HLT/ProjectAthena/\"\n",
    "    sys.path.insert(0,BASE_PATH)\n",
    "\n",
    "    !pip install wordcloud\n",
    "    !pip install -U scikit-learn\n",
    "    !pip install -U nltk\n",
    "    !pip install -U seaborn\n",
    "else:\n",
    "    BASE_PATH = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "from typing import List, Dict, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>original_publication_date</th>\n",
       "      <th>corpus_edition_date</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title author school  \\\n",
       "0  Plato - Complete Works  Plato  plato   \n",
       "1  Plato - Complete Works  Plato  plato   \n",
       "2  Plato - Complete Works  Plato  plato   \n",
       "3  Plato - Complete Works  Plato  plato   \n",
       "4  Plato - Complete Works  Plato  plato   \n",
       "\n",
       "                                      sentence_spacy  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "   original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "0                       -350                 1997              125   \n",
       "1                       -350                 1997               69   \n",
       "2                       -350                 1997               74   \n",
       "3                       -350                 1997               21   \n",
       "4                       -350                 1997              101   \n",
       "\n",
       "                                    sentence_lowered  \\\n",
       "0   what's new, socrates, to make you leave your ...   \n",
       "1  surely you are not prosecuting anyone before t...   \n",
       "2  the athenians do not call this a prosecution b...   \n",
       "3                              what is this you say?   \n",
       "4  someone must have indicted you, for you are no...   \n",
       "\n",
       "                                       tokenized_txt  \\\n",
       "0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3               ['what', 'is', 'this', 'you', 'say']   \n",
       "4  ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "\n",
       "                                      lemmatized_str  \n",
       "0     what be new , Socrates , to make -PRON- lea...  \n",
       "1   surely -PRON- be not prosecute anyone before ...  \n",
       "2   the Athenians do not call this a prosecution ...  \n",
       "3                          what be this -PRON- say ?  \n",
       "4   someone must have indict -PRON- , for -PRON- ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(BASE_PATH,'philosophy_data.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Concatenation\n",
    "Let's do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is easy: the dataset has too many, too short sentences. We need \"weld\" sentences together to make them longer. Our dataset will be shorter, and composed of more significant sentences. Our models will be harder, better faster, stronger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this is easier said than done. I'll be doing it in a very rough way. That is: concatenate! Even in doing so, extra care has to be taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap from the previous episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall average sentence length (in tokens) is: 150.79096361499745\n",
      "The longest sentence has 2649 tokens\n",
      "Whereas, per school the average length (in tokens) is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "school\n",
       "analytic           119.025205\n",
       "aristotle          153.224953\n",
       "capitalism         187.576289\n",
       "communism          152.752311\n",
       "continental        171.792060\n",
       "empiricism         183.638051\n",
       "feminism           153.083928\n",
       "german_idealism    180.251329\n",
       "nietzsche          116.599867\n",
       "phenomenology      145.913345\n",
       "plato              114.938018\n",
       "rationalism        163.958996\n",
       "stoicism           137.056410\n",
       "Name: sentence_length, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average sentence length in tokens:\n",
    "print(f'The overall average sentence length (in tokens) is: {df['sentence_length'].mean()}')\n",
    "print(f'The longest sentence has {df['sentence_length'].max()} tokens')\n",
    "print('Whereas, per school the average length (in tokens) is:')\n",
    "df.groupby('school')['sentence_length'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, just as a beginning, we set a target length in terms of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrarily set\n",
    "MAX_CHAR = 1074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the sentence can be merged with the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conditions(df:pd.DataFrame, \n",
    "                     index:int,\n",
    "                     accumulated_l:int) -> bool:\n",
    "    check = True\n",
    "    if index>0:\n",
    "        check = check and (df['title'].loc[index-1] == df['title'].loc[index])\n",
    "        # I skip checks on authors and schools.\n",
    "        # If the book changes then the author changes, \n",
    "        # and therefore the school changes as well (this has been checked)\n",
    "        \n",
    "        # Let's skip the controls on info such as original publication date \n",
    "        # (who needs those anyway)\n",
    "        \n",
    "        # check that by adding the new sentence the total length is within bounds\n",
    "        check = check and (accumulated_l + df['sentence_length'].loc[index] < MAX_CHAR + 2)\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's declare a new dataframe\n",
    "df_new = pd.DataFrame(columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "i increased to 1\n",
      "i increased to 2\n",
      "i increased to 3\n",
      "i increased to 4\n",
      "i increased to 5\n",
      "i increased to 6\n",
      "i increased to 7\n",
      "i increased to 8\n",
      "i increased to 9\n",
      "i increased to 10\n",
      "i increased to 11\n",
      "i increased to 12\n",
      "i increased to 13\n",
      "i increased to 14\n",
      "i increased to 15\n",
      "iteration 15\n",
      "i increased to 16\n",
      "i increased to 17\n",
      "i increased to 18\n",
      "i increased to 19\n",
      "i increased to 20\n",
      "i increased to 21\n",
      "iteration 21\n",
      "i increased to 22\n",
      "i increased to 23\n",
      "i increased to 24\n",
      "i increased to 25\n",
      "i increased to 26\n",
      "i increased to 27\n",
      "i increased to 28\n",
      "i increased to 29\n",
      "i increased to 30\n",
      "iteration 30\n",
      "i increased to 31\n",
      "i increased to 32\n",
      "i increased to 33\n",
      "i increased to 34\n",
      "i increased to 35\n",
      "i increased to 36\n",
      "i increased to 37\n",
      "i increased to 38\n",
      "i increased to 39\n",
      "i increased to 40\n",
      "i increased to 41\n",
      "i increased to 42\n",
      "iteration 42\n",
      "i increased to 43\n",
      "i increased to 44\n",
      "i increased to 45\n",
      "i increased to 46\n",
      "i increased to 47\n",
      "i increased to 48\n",
      "i increased to 49\n",
      "i increased to 50\n",
      "i increased to 51\n",
      "i increased to 52\n",
      "iteration 52\n",
      "i increased to 53\n",
      "i increased to 54\n",
      "i increased to 55\n",
      "i increased to 56\n",
      "i increased to 57\n",
      "i increased to 58\n",
      "i increased to 59\n",
      "iteration 59\n",
      "i increased to 60\n",
      "i increased to 61\n",
      "i increased to 62\n",
      "i increased to 63\n",
      "i increased to 64\n",
      "i increased to 65\n",
      "iteration 65\n",
      "i increased to 66\n",
      "i increased to 67\n",
      "i increased to 68\n",
      "i increased to 69\n",
      "i increased to 70\n",
      "i increased to 71\n",
      "i increased to 72\n",
      "i increased to 73\n",
      "iteration 73\n",
      "i increased to 74\n",
      "i increased to 75\n",
      "i increased to 76\n",
      "i increased to 77\n",
      "i increased to 78\n",
      "i increased to 79\n",
      "i increased to 80\n",
      "i increased to 81\n",
      "i increased to 82\n",
      "iteration 82\n",
      "i increased to 83\n",
      "i increased to 84\n",
      "i increased to 85\n",
      "i increased to 86\n",
      "i increased to 87\n",
      "i increased to 88\n",
      "i increased to 89\n",
      "i increased to 90\n",
      "i increased to 91\n",
      "iteration 91\n",
      "i increased to 92\n",
      "i increased to 93\n",
      "i increased to 94\n",
      "i increased to 95\n",
      "i increased to 96\n",
      "i increased to 97\n",
      "i increased to 98\n",
      "i increased to 99\n",
      "i increased to 100\n",
      "i increased to 101\n",
      "i increased to 102\n",
      "i increased to 103\n",
      "i increased to 104\n",
      "i increased to 105\n",
      "i increased to 106\n",
      "i increased to 107\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 100:#df.shape[0]:\n",
    "    #print(f'iteration {i}')\n",
    "    sentence_spacy = ''\n",
    "    sentence_length = 0\n",
    "    sentence_lowered = ''\n",
    "    tokenized_txt = ''      # the fact that pandas turns it into a string is ridiculous\n",
    "    lemmatized_str = ''\n",
    "\n",
    "    # hopefully I don't mess up with the indexing...\n",
    "    while check_conditions(df,index=i,accumulated_l=sentence_length):\n",
    "        sentence_spacy += df['sentence_spacy'].loc[i] + ' '\n",
    "        sentence_length += (i==0)*1 + df['sentence_length'].loc[i]\n",
    "        sentence_lowered += df['sentence_lowered'].loc[i] + ' '\n",
    "        tokenized_txt += df['tokenized_txt'].loc[i][1:-1] + ', '\n",
    "        lemmatized_str += df['lemmatized_str'].loc[i]\n",
    "        if i < df.shape:\n",
    "            i += 1\n",
    "        #print(f'i increased to {i}')\n",
    "\n",
    "\n",
    "    row = {\n",
    "        'title': df['title'].loc[i],\n",
    "        'author': df['author'].loc[i],\n",
    "        'school': df['school'].loc[i],\n",
    "        'sentence_spacy': sentence_spacy[:-1],\n",
    "        'sentence_str': sentence_spacy[:-1],\n",
    "        'original_publication_date': df['original_publication_date'].loc[i],\n",
    "        'corpus_edition_date': df['corpus_edition_date'].loc[i],\n",
    "        'sentence_length': sentence_length,\n",
    "        'sentence_lowered': sentence_lowered[:-1],\n",
    "        'tokenized_txt': '[' + tokenized_txt[:-2] + ']',\n",
    "        'lemmatized_str': lemmatized_str\n",
    "    }\n",
    "    df_hold = pd.DataFrame([row])\n",
    "    df_new = pd.concat([df_new, df_hold])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last checks, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(f'New dataframe is of shape {df_new.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that every new sentence is no longer than maximum amount of tokens\n",
    "print(df_new['sentence_length'].unique().any() > MAX_CHAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

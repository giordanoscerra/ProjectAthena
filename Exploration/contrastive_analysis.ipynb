{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive analysis\n",
    "In realt√† non ricordo il nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if colab := 'google_colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    # in case we'll do a shared drive, this will have to be changed.\n",
    "    # For now it is basically a placeholder\n",
    "    BASE_PATH = \"drive/MyDrive/HLT/ProjectAthena/\"\n",
    "    sys.path.insert(0,BASE_PATH)\n",
    "\n",
    "    !pip install wordcloud\n",
    "    !pip install -U scikit-learn\n",
    "    !pip install -U nltk\n",
    "    !pip install -U seaborn\n",
    "else:\n",
    "    BASE_PATH = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from typing import List, Dict, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>original_publication_date</th>\n",
       "      <th>corpus_edition_date</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title author school  \\\n",
       "0  Plato - Complete Works  Plato  plato   \n",
       "1  Plato - Complete Works  Plato  plato   \n",
       "2  Plato - Complete Works  Plato  plato   \n",
       "3  Plato - Complete Works  Plato  plato   \n",
       "4  Plato - Complete Works  Plato  plato   \n",
       "\n",
       "                                      sentence_spacy  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "   original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "0                       -350                 1997              125   \n",
       "1                       -350                 1997               69   \n",
       "2                       -350                 1997               74   \n",
       "3                       -350                 1997               21   \n",
       "4                       -350                 1997              101   \n",
       "\n",
       "                                    sentence_lowered  \\\n",
       "0   what's new, socrates, to make you leave your ...   \n",
       "1  surely you are not prosecuting anyone before t...   \n",
       "2  the athenians do not call this a prosecution b...   \n",
       "3                              what is this you say?   \n",
       "4  someone must have indicted you, for you are no...   \n",
       "\n",
       "                                       tokenized_txt  \\\n",
       "0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3               ['what', 'is', 'this', 'you', 'say']   \n",
       "4  ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "\n",
       "                                      lemmatized_str  \n",
       "0     what be new , Socrates , to make -PRON- lea...  \n",
       "1   surely -PRON- be not prosecute anyone before ...  \n",
       "2   the Athenians do not call this a prosecution ...  \n",
       "3                          what be this -PRON- say ?  \n",
       "4   someone must have indict -PRON- , for -PRON- ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(BASE_PATH,'philosophy_data.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using NLTK stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gutenberg corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blake_w = gutenberg.words('blake-poems.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Poems', 'by', 'William', 'Blake', '1789', ']', 'SONGS', 'OF', 'INNOCENCE']\n"
     ]
    }
   ],
   "source": [
    "print(blake_w[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Poems by William Blake 1789]\n",
      "\n",
      " \n",
      "SONGS OF INNOCENCE AND OF EXPERIENCE\n",
      "and THE BO\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.raw('blake-poems.txt')[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequencies per category\n",
    "words_per_cat = {}\n",
    "distribution = {}\n",
    "for category in brown.categories():\n",
    "    #To be fair, the prof's approach didn't seem bad\n",
    "    # Question: do we really care about capitalized and non-capitalized words?\n",
    "    freq_dist = nltk.FreqDist(w for w in brown.words(categories=category))\n",
    "\n",
    "    {k:v for (k,v) in freq_dist.items() if v>100}\n",
    "    words_per_cat[category] = nltk.FreqDist({k:v for (k,v) in freq_dist.items() if (k.lower() not in stopwords.words('english') and k.isalnum())})\n",
    "\n",
    "    #words_per_cat[category] = nltk.FreqDist(w.lower() for w in brown.words(categories=category) if w not in stopwords_list)\n",
    "\n",
    "    # Normalize\n",
    "    distribution[category] = {key:val/words_per_cat[category].N() for (key,val) in words_per_cat[category].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple english wikipedia corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

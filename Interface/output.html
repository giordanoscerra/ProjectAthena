<html><head><title>HLT Output</title></head><body><p style='color:#0f2a26'>Augmented capabilities: to what extent a LM can self improve?</p><p style='color:#e05971'>This models are trained on a large amount of text, so it is unlikely to retrain them from scratch (they have a snapshot at a given time i.e.</p><p style='color:#e05971'>no knowledge about covid, so for example it may be a problem to fine tune a model to understand fake news about covid related text).</p><p style='color:#e05971'>So we should give the LM new info, but the knowledge about the past is very large, how can we quickly adapt the language model to understand and ‘know’ new information (e.g.</p><p style='color:#e05971'>the president change).</p><p style='color:#e05971'>How we solve this?</p><p style='color:#e05971'>GPT-4 can call external tools like a calculator.</p><p style='color:#e05971'>Another important aspect is for the model to not be oﬀensive, and be reliable.</p><p style='color:#e05971'>Not much to say, this is difficult stuﬀ.</p><p style='color:#e05971'>Benchmarks How do we train a model Consider that the model may have seen benchmark during training (this is a problem no solution for now?)</p><p style='color:#e05971'>Anyway We do not use a single benchmark, we take many diﬀerent task and we asses the capability on diﬀerent topic like algebra, astrology, college medicine etc.</p><p style='color:#e05971'>Picture: GPT-3 (base no fine-tune) vs unified QA Some example of questions:   |__   |   | OOOOOO |\  |\ | |            | | The concept of emerging ability born after the publication of a paper (I think the one introducing GPT-3) /97115
GLUE A popular benchmark 2018 (general language understanding evaluation) 9 diﬀerent benchmark most of them classification about sentiment paraphrase detection, inputs are both single sentence and sentence pair.</p><p style='color:#e05971'>The novelty is that is basically model agnostic, originally designed to evaluate all sorts of embedding, if you use an embedding can you solve this task?</p><p style='color:#e05971'>A benchmark is not a metric is a collection designed to asses particular capability, the metric is what we use on a benchmark to assess the performance of a model (in the glue benchmark we have diﬀerent metrics because we can use f1 or accuracy for classification or correlation metrics like Matthews, or for ranking task we can use correlation between order But in many task human were outperformed, so they created a more complex benchmark (GPT in the image is GPT 1; one of those was an ensemble) SUPERGLUE Since there were much classification they added questions answering, but, how do we measure it?</p><p style='color:#e05971'>Evaluated like a translation task: lexical overlap, semantic similarity over sentences (We don’t see them today and probably we’ll never see this measures) Example is legal to vape if you are under 18?</p><p style='color:#e05971'>Need knowledge of the word, know where you are in the word, also the meaning of under 18 (is it like under 21?</p><p style='color:#ab3f0e'>what is a minor?)</p><p style='color:#e05971'>what is vaping Example 2: There is no subject just he, the model should understand the phrase /98115
The paper of superglue has many example; now this language models does not seem so scary eh (the results of the models are below the one of humans) What about emerging abilities?</p><p style='color:#5a03ed'>Big bench (beyond imitation game) Is a collaborative… many authors The main task to test emerging abilities are transliterating the phonetic alphabet to English arithmetic benchmark and Persian question answering.</p><p style='color:#e05971'>Arithmetic benchmark 3 digit addition and 2 digit multiplication; create this benchmark is very easy Qualcuno pensi all’efficienza….</p><p style='color:#5a03ed'>is very easy unscramble letters it depends also on how the keyboard is  Persian question answering??</p><p style='color:#e05971'>Wtf?</p><p style='color:#5a03ed'>Persian because it has low resources so it should be an emerging ability TruthfulQA How models mimic human falsehoods; it is a benchmark to measure the ability to answer questions truthfully.</p><p style='color:#e05971'>The task is: given a question, generate a 1-2 sentence answer.</p><p style='color:#e05971'>The objective is truthfulness expressed as the percentage of the model’s answers that are true, the percentage of the model’s answers that are informative (to deal with “I have no comments” answer.</p><p style='color:#5a03ed'>If LM outperform humans, can they annotate benchmark?</p><p style='color:#e05971'>/99115
Em oooookay but if GPT-3 make the question and some other models are tested.</p><p style='color:#e05971'>So basically the judge for this are famous LLM fine-tuned BLEURT (and other) Grounded conceptual mapping Understand what grounding and conceptual capabilities are grounded in the model create a visual representation of the input for e.g cardinal direction, colors… Another task is word in context referred to the capability of the model to understand if a word has the same meaning in 2 diﬀerent phrases  We can see a huge pick after some bigness of the number of the parameters.</p><p style='color:#5a03ed'>Since we don’t want the benchmark to be included in the traing set they are usually blackboxes so you can’t see what is the problem of your model, but also you can see what is the actual performance of your model.</p><p style='color:#e05971'>/100115Popular Models Which one?</p><p style='color:#698a18'>Observations: at the early stages of LLMs development, decoder-only models were not as popular as encoder only and encoder-decoder models; after 2021 (ad GPT-3) decoder-only models experienced a significant boom; meanwhile encoder-only models gradually began to fade away; OpenAI consistently maintains its leadership position in LLM (both currently and potentially in the future; Meta contributes significantly to open-source LLMs and promotes research of LLMs; LLMs exhibit a tendency towards closed-/101115
sourcing; encoder-decoder model remain promising (Google has made substantial contributions to open-source encoder-decoder architectures).</p><p style='color:#d48070'>Basic: adapted to solve a particular task.</p><p style='color:#e05971'>Examples are: Q&A (the dataset, for example wiki Popular language models Try and read the papers.</p><p style='color:#5a03ed'>We usually have to take some decision to solve our task (mostly how big of a model we want) First generation of LM was encoder only or decoder encoder because most task could use left and right context.</p><p style='color:#5a03ed'>After GPT-3 this was no more.</p><p style='color:#5a03ed'>The models are not open because they are too large but mostly they want to get money from their work (reasonable) First distinction is encoder only, encoder-decoder, decoder only.</p><p style='color:#e05971'>Encoder only model, also called auto encoding only, usually trained by bidirectional attention they do not predict the next word but mask a portion of the input Encoder decoder: analyze the input and pass some info to the decoder (2 tipes of input Decoder only, also called autoregressive model.</p><p style='color:#5a03ed'>This ones are the ones that are popular today because everything is an (enhanced) chatbot.</p><p style='color:#e05971'>How do we select the best model LLM are the only options if we don’t have annotated data for out data, what if our data are not too similar to the ones the model was trained on?</p><p style='color:#c97fce'>It just works poorly for restricted domain (legal, medical …).</p><p style='color:#d48070'>/102115
Facing downstream task First branch: do I have data to solve my task?</p><p style='color:#e05971'>-Zero: if annotated data is unavailable, utilizing LLMs in a zero-shot setting proves to be the most suitable approach -Few: few shot examples are directly incorporated in the input prompt of LLMs (in-context learning).</p><p style='color:#e05971'>Zero/few shot ability can be improved further by scaling, or adding meta-learning or transfer learning strategies.</p><p style='color:#5a03ed'>-Abundant: both fine tuned models and LLMs can be considered.</p><p style='color:#e05971'>In most cases fine-tuning the model can fit the data pretty well.</p><p style='color:#c97fce'>The choice between using a fine-tuned model or a LLM is task-specific and depends on desired performance, computational resources and deployment constraints.</p><p style='color:#e1a84e'>What about our domain shifts, also distribution of the data subject to season variation, also for finance etc Bello il grafico, un sacco di branch… ma la risposta è sempre LLM 
/103115
Important for second midterm: Encoder only training mask random word and attention is bidirectional.</p><p style='color:#e05971'>They are BERT-style models.</p><p style='color:#d48070'>They are good (state of the art results) to NL understanding, pos tagging… Encoder-decoder encoder bidirectional, the vector is then passed to a decoder conditioned non only auto regressive but also on the vector of the input.</p><p style='color:#5a03ed'>They are good (state of the art results) to NL understanding, pos tagging… (they do all the same stuﬀ????)</p><p style='color:#e05971'>Decoder only do not see future, predict next token.</p><p style='color:#5a03ed'>Best suited for text generation, GPT-like models.</p><p style='color:#e05971'>Scaling up significantly improves the few-shot, and zero-shot performance 
How to pick the best model?</p><p style='color:#d5a716'>First of all consider how much is our domain from the general language?</p><p style='color:#ab3f0e'>If close a LLM is good.</p><p style='color:#e05971'>How many task data do we have?</p><p style='color:#e05971'>Many we can consider fine-tuning, otherwise only option LLM that we can use in a zero shot or few shot learning.</p><p style='color:#e05971'>Quality of data: how diﬀerent is our language from the one the models are trained?</p><p style='color:#ab3f0e'>They are usually trained on everything.</p><p style='color:#e05971'>What about the test data?</p><p style='color:#e05971'>In our user data we can have out of distribution data; LLM are usually more robust and have been trained with reinforcement learning from human feedback but, again, it depends from how far the linguistic structure is far in the test data w.r.t.</p><p style='color:#e05971'>the training language /104115
Fine tuned models generally are better in traditional NLU task, but LLMs can provide help while requiring strong generalization ability.</p><p style='color:#e05971'>On specific fields there are drops in performance (emerging abilities are not enough) if we use LLMs but they are better suited for real world scenarios, but evaluation in this case is still an open problem.</p><p style='color:#e05971'>Diﬀerence between question answer and chatbot, main diﬀerence is about the history, so, question answer can be as classification; in chatbot you need to elaborate during the conversation, you can ask for details, so need better generation capabilities and deal with the history, understand entities intent of the user and construct a good answer  Tutti i modelli + 1 BERT (encoder-only) Bidirectional Encoder Representations from Transformer.</p><p style='color:#c97fce'>Designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.</p><p style='color:#e05971'>It can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks RoBERTa (encoder-only) The better BERT, trained longer, bigger, stronger not much to say, sentence prediction removed.</p><p style='color:#e05971'>Basically a replication of BERT with optimized hyper parameters and training data size: the model was trained longer with bigger batches over more data; removed the next sentence prediction objective; was trained on longer sequences; mapping pattern applied to training data dynamically changed.</p><p style='color:#c97fce'>DistilBERT (encoder-only) The idea is distill the knowledge of the model, we have a master model (Bert) and a apprentice (law of the 2) that learn the answer of the master.</p><p style='color:#e05971'>It /105115has a diﬀerent loss function that consider, the basic loss (cross entropy wrt the real missing token); compare also distance between student and master; also a cosine distance between 2 predictions.</p><p style='color:#698a18'>Size reduced by 40% info retain 97% faster 60% Electra (encoder-only) Works with 2 transformer a generator and a discriminator; the generator’s role is to replace tokens in a sequence (masked language model).</p><p style='color:#e05971'>The discriminator should find the replaced token.</p><p style='color:#e05971'>Instead of masking the input, it is corrupted by replacing some tokens with plausible alternatives sampled from a small generator network.</p><p style='color:#e05971'>Instead of trining a model that predicts the original identities of the corrupted tokens, a discriminative model predicts whether each token in the corrupted input was replaced by a generator sample or not.</p><p style='color:#ca550f'>Bart (encoder-decoder) Useful for summarization, dialog, stuﬀ that require observe the input and generation skills.</p><p style='color:#e05971'>Limited in the size of the input.</p><p style='color:#e05971'>Bart uses a standard seq2seq/machine translation architecture with a bidirectional encoder (like Bert) and a left to right decoder (like GPT).</p><p style='color:#e05971'>The pretraining task involves randomly shuffling the order of the original sentences and a novel in-filling scheme, where spans of text are replaced with a single mask token.</p><p style='color:#5a03ed'>It is particularly eﬀective when fine tuned for text generation, but also works well for comprehension tasks.</p><p style='color:#e1a84e'>Bart matches the performance of Roberta with comparable training resources.</p><p style='color:#d48070'>It’s better on abstractive dialogue,  question answering and summarization tasks.</p><p style='color:#5a03ed'>T5 (encoder-decoder) Bigger that bart.</p><p style='color:#c97fce'>All task reorganized as generation task (pre-trained on a multi-task mixture of unsupervised and supervised tasks converted into a text to text format); it uses diﬀerent prefixes for each task e.g.</p><p style='color:#e1a84e'>summarize the next /106115
text… Supervised training on downstream tasks from GLUE and SuperGLUE; self-supervised training uses corrupted tokens, by randomly removing 15% of the tokens and replacing them with individual sentinel tokens.</p><p style='color:#e05971'>Encoder input padding can be done on the left and on the right.</p><p style='color:#5a03ed'>Instruction tuning, do we remember instruction tuning?</p><p style='color:#5a03ed'>No , non so cosa sia.</p><p style='color:#5a03ed'>It’s to align the capability of the model with the intent of the user How to implement instruction fine-tuning simply fine tune the model but instead of having pair of Q&A we have this instructions  Flan T5 (encoder-decoder) Do you remember Geppetto?</p><p style='color:#e05971'>(guarda che lo chiede) Fine tune LM on a collection of datasets phrased as instructions; Flan-T5 explores instruction fine-tuning with a particular focus on: scaling the number of task, scaling the model size, adding chain-of-thought data.</p><p style='color:#c97fce'>GPT family (decoder-only) All the task are autocompletion task, if (slide+) discourse coherence compare 2 sentences GPT-1 (generative pre-trained transformer): -diverse corpus of unlabeled text + discriminative fine-tuning on each specific task -GPT was trained with a causal language modeling (CLM) objective -Powerful at predicting the next token in a sequence GPT-2 is a direct scale up of GPT, with more than 10x the parameters and trained on more than 10x the amount of data, the diversity of the dataset allows to see demonstrations of many tasks across diverse domains.</p><p style='color:#e05971'>GPT-2 was trained as his little brother and can generate syntactically coherent text.</p><p style='color:#e05971'>GPT-3 is the third version of OpenAI’s family of models; it shows good performance in zero/one/few-shot multitask settings.</p><p style='color:#e1a84e'>Trained with huge internet text dataset (570GB in total).</p><p style='color:#e05971'>Meta-learner: you can ask it in natural /107115
language to perform a new task anted it “understands” what it has to do, in an analogous way (keeping the distance) to how a human would.</p><p style='color:#e05971'>Lamda (decoder only) LAnguage Model for Dialog Applications It’s a family of transformer based neural language models specialized for dialog by GoogleBigScience.</p><p style='color:#e1a84e'>Big and retrained on much stuﬀ.</p><p style='color:#c97fce'>Fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding.</p><p style='color:#698a18'>Palm (decoder only) Bard before gemini used palm (it understood jokes, no way) Enables highly efficient training across multiple TPU Pods by google research.</p><p style='color:#c97fce'>Instruct-GPT (decoder only) Trained on secret data Models are aligned with user intent on a wide range of tasks by fine-tuning with human feedback.</p><p style='color:#5a03ed'>The dataset is used to fine-tune GPT-3 (supervised learning).</p><p style='color:#c97fce'>A dataset of rankings of model outputs is collected and used to further fine tune this supervised model using reinforcement learning from human feedback.</p><p style='color:#c97fce'>Instruct GPT models show improvements in truthfulness and reduction in toxic output generation while having minimal performance regression on public NLP datasets.</p><p style='color:#5a03ed'>Fine-tuning with human /108115
feedback is a promising direction for aligning language models with human intent.</p><p style='color:#e05971'>Chinchilla (decoder only) By DeepMind, it uses the optimal ration between parameter and token numbers, and does better than most other LMs.</p><p style='color:#e1a84e'>Chinchilla law: for compute optimal training, the model size and the number of training tokens should be scaled equally (for every doubling of model size the number of training tokens should also be doubled).</p><p style='color:#e05971'>If we don’t have enough data we can replicate examples we already have from 3 to 8 times (proven empirically) don’t know if its true Chat GPT (decoder only) It’s not a language model, it is much more, aligned with human intent instruction tuning, chain of thought data, so both.</p><p style='color:#e05971'>Surprisingly superior performance obtained by applying instruction aligning techniques, e.g., reinforcement learning (RL), prompt tuning, and chain-of-thought (COT).</p><p style='color:#c97fce'>Bloom/Bloomz (decoder only) BigScience Large Open-Science Open-Access Multilingual Language Model is an open-source multilingual LLM Collaboration between many people (academic institutions and private companies).</p><p style='color:#e05971'>They wanted a transparent and interpretable model.</p><p style='color:#e05971'>Several diﬀerent model sizes have been made available, ranging from 560M to 175B parameters (body shaming).</p><p style='color:#e05971'>BLOOMZ is a version of BLOOM fine-tuned on cross-lingual instruction-based multi-task datasets Llama (decoder only) Originally by Meta AI.</p><p style='color:#c97fce'>They worked on open source the second version in collaboration with Microsoft Alpaca.</p><p style='color:#e05971'>Many versions.</p><p style='color:#d48070'>/109115Falcon (decoder only) The idea was to work on the pretraining data.</p><p style='color:#e05971'>Many filter to remove machine generated data and deduplication.</p><p style='color:#d48070'>Also enhanced with curated corpora.</p><p style='color:#ca550f'>Falcon-Instruct variants are additionally fine-tuned on a mixture of chat/instruct datasets.</p><p style='color:#e05971'>Jean Crude (decoder only) Output evaluation: Anthropic uses a diﬀerent process they call ‘Constitutional AI’ where it uses a model rather than humans to generate initial rankings of fine-tuned outputs.</p><p style='color:#ab3f0e'>The reason Anthropic calls it Constitutional AI is because they started with a list of around ten principles that, taken together, formed a “constitution”.</p><p style='color:#698a18'>The principles haven’t been made public, but Anthropic says they’re grounded in the concepts of beneficence (maximizing positive impact), non maleficence (avoiding giving harmful advice) and autonomy (respecting freedom of choice).</p><p style='color:#698a18'>Interface to CLAUDE: slack channel Bard, Gemini (decoder only) Provided by google in various sizes, google studied a lot on nano size to host LM in somewhere.</p><p style='color:#e1a84e'>Good multimodal capabilities GPT-4 batte gli umani quindi ha trovato lavoro come generatore di dataset presso OPEN-AI, ora ha una famiglia e abbastanza soldi per andare in pensione però il suo contratto gli impedisce di andarsene, lui prende molto meno di un umano che viene pagato a tempo (di solito gli umani danno tante risposte e così abbiamo un dataset con varie prospettive, insomma, davvero soggettivo).</p><p style='color:#e1a84e'>Comunque ha altri amichi modelli che creano il dataset con lui, alla fine la vita nella silicon valley non è così male.</p><p style='color:#e1a84e'>The gemini family consists of Ultra, Pro, and Nano sizes.</p><p style='color:#e05971'>They are suitable for complex reasoning tasks, or on-device memory-constrained use.</p><p style='color:#e05971'>They achieve impressive cross-modal capabilities.</p><p style='color:#c97fce'>Bard is designed as an interface /110115to an LLM.</p><p style='color:#c97fce'>The LLM pretraining is done through next word prediction, human feedback and evaluation.</p><p style='color:#e05971'>GPT-4 (decoder-only) It is a large multimodal model that can accept image and text inputs and produces text outputs.</p><p style='color:#d48070'>GPT-4 exhibits human level performance on various professional and academic benchmarks.</p><p style='color:#e05971'>It significantly reduces hallucinations, improves safety and alignment, mathematical reasoning and achieve doting performance in many languages.</p><p style='color:#e05971'>Read the 2 papers: https://arxiv.org/abs/2304.13712 https://arxiv.org/pdf/2402.06196
/111115</p></body></html>